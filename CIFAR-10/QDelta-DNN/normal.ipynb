{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from modules.ir_1w1a import Nomal_conv2d\n",
    "from modules.ir_1w1a import Nomal_linear\n",
    "from modules import ir_1w1a\n",
    "from vgg import VGG_SMALL_1W1A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import my_model\n",
    "\n",
    "# Hyper parameters\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load data\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../../data', train=True, download=True,\n",
    "                                        transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../../data', train=False, download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def train(net, epoch=0):\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    print('\\nEpoch: %d' % (epoch+1))\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print('-', end='')\n",
    "    print('\\nTrain: Loss: {:.3f} | Acc: {:.3f}%% ({}/{})'.\n",
    "          format(train_loss, 100. * correct / total, correct, total))\n",
    "    return 100. * correct / total\n",
    "\n",
    "\n",
    "def test(net):\n",
    "    global best_acc\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        print('Test: Loss: {:.3f} | Acc: {:.3f}%% ({}/{})'.\n",
    "              format(test_loss, 100. * correct / total, correct, total))\n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train: Loss: 423.004 | Acc: 25.614%% (12807/50000)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "25.614"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model = my_model.VGG_SMALL_allnormal(q_bit=16).cuda()\n",
    "lr = 0.007\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, epochs, eta_min=0, last_epoch=-1)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test: Loss: 82.213 | Acc: 30.150%% (3015/10000)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30.15"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 将卷积层和bn层合并\n",
    "def fuse(conv, bn):\n",
    "    w = conv.weight\n",
    "    mean = bn.running_mean\n",
    "    var_sqrt = torch.sqrt(bn.running_var + bn.eps)\n",
    "\n",
    "    beta = bn.weight\n",
    "    gamma = bn.bias\n",
    "\n",
    "    if conv.bias is not None:\n",
    "        b = conv.bias\n",
    "    else:\n",
    "        b = mean.new_zeros(mean.shape)\n",
    "\n",
    "    w = w * (beta / var_sqrt).reshape([conv.out_channels, 1, 1, 1])\n",
    "    b = (b - mean)/var_sqrt * beta + gamma\n",
    "    fused_conv = nn.Conv2d(conv.in_channels,\n",
    "                         conv.out_channels,\n",
    "                         conv.kernel_size,\n",
    "                         conv.stride,\n",
    "                         conv.padding,\n",
    "                         bias=True)\n",
    "    fused_conv.weight = nn.Parameter(w)\n",
    "    fused_conv.bias = nn.Parameter(b)\n",
    "    return fused_conv\n",
    "\n",
    "\n",
    "class DummyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyModule, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Dummy, Dummy.\")\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def fuse_module(m):\n",
    "    children = list(m.named_children())\n",
    "    c = None\n",
    "    cn = None\n",
    "\n",
    "    for name, child in children:\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            bc = fuse(c, child)\n",
    "            m._modules[cn] = bc\n",
    "            m._modules[name] = DummyModule()\n",
    "            c = None\n",
    "        elif isinstance(child, nn.Conv2d):\n",
    "            c = child\n",
    "            cn = name\n",
    "        else:\n",
    "            fuse_module(child)\n",
    "\n",
    "ttt=fuse(model.conv0,model.bn0).weight\n",
    "print(ttt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/753 [00:00<?, ?it/s]clean the  ./part_diff/245.out\n",
      "  0%|          | 1/753 [00:01<18:21,  1.47s/it]clean the  ./part_diff/246.out\n",
      "  0%|          | 1/753 [00:02<30:51,  2.46s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d2db94cd0b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mxnor_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msecond5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mxnor_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbi_list_To_uint8_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnor_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxnor_diff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mbinfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-d2db94cd0b16>\u001b[0m in \u001b[0;36mbi_list_To_uint8_list\u001b[0;34m(bi_list, n_1, n_0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbi_list_To_uint8_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbi_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbi_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlenth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import struct\n",
    "import os\n",
    "import time\n",
    "####################################################################################\n",
    "## 将二进制的权重的list组合成uint8的list，便于写入文件\n",
    "def bi_list_To_uint8_list(bi_list,n_1=1.0,n_0=-1.0):\n",
    "    if type(bi_list)==numpy.ndarray:\n",
    "        bi_list=bi_list.tolist()\n",
    "    lenth=len(bi_list)\n",
    "\n",
    "    # 对齐到字节\n",
    "    if lenth%8!=0:\n",
    "        for i in range(8-(lenth%8)):\n",
    "            bi_list.append(n_0)\n",
    "        lenth=lenth+8-lenth%8\n",
    "\n",
    "    uint8_list=[]\n",
    "\n",
    "    for i in range(lenth):\n",
    "        if bi_list[i]==n_1:\n",
    "            bi_list[i]=1\n",
    "        elif bi_list[i]==n_0:\n",
    "            bi_list[i]=0\n",
    "        elif bi_list[i]==0.0:\n",
    "            bi_list[i]=1\n",
    "        else:\n",
    "            print('error',bi_list[i])\n",
    "            return\n",
    "\n",
    "    for i in range(0,lenth,8):\n",
    "        uint8_i=bi_list[i]*128+bi_list[i+1]*64+bi_list[i+2]*32+bi_list[i+3]*16+bi_list[i+4]*8+bi_list[i+5]*4+bi_list[i+6]*2+bi_list[i+7]\n",
    "        uint8_i=int(uint8_i)\n",
    "        uint8_list.append(uint8_i)\n",
    "    return uint8_list\n",
    "\n",
    "####################################################################################\n",
    "model_path='./out/partnormal88.97/'\n",
    "model = my_model.VGG_SMALL_1W1A_normal().cuda()\n",
    "\n",
    "for i in tqdm(range(245,998)):\n",
    "\n",
    "    ####################################################################################\n",
    "    ### 保存两个版本的参数\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path+str(i)+'.ckpt'))\n",
    "    first0=numpy.round(127*model.conv0.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    ## 1-5为二值化层\n",
    "    first1=model.conv1.true_weight().detach().cpu().numpy().ravel()\n",
    "    first2=model.conv2.true_weight().detach().cpu().numpy().ravel()\n",
    "    first3=model.conv3.true_weight().detach().cpu().numpy().ravel()\n",
    "    first4=model.conv4.true_weight().detach().cpu().numpy().ravel()\n",
    "    first5=model.conv5.true_weight().detach().cpu().numpy().ravel()\n",
    "\n",
    "\n",
    "    first_fc_weight=numpy.round(127*model.fc.true_weight()[0].detach().cpu().numpy().ravel()).astype(int)\n",
    "    first_fc_bias=numpy.round(127*model.fc.true_weight()[1].detach().cpu().numpy().ravel()).astype(int)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path+str(i+1)+'.ckpt'))\n",
    "    second0=numpy.round(127*model.conv0.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second1=model.conv1.true_weight().detach().cpu().numpy().ravel()\n",
    "    ## 1-5为二值化层\n",
    "    second1=model.conv1.true_weight().detach().cpu().numpy().ravel()\n",
    "    second2=model.conv2.true_weight().detach().cpu().numpy().ravel()\n",
    "    second3=model.conv3.true_weight().detach().cpu().numpy().ravel()\n",
    "    second4=model.conv4.true_weight().detach().cpu().numpy().ravel()\n",
    "    second5=model.conv5.true_weight().detach().cpu().numpy().ravel()\n",
    "    second_fc_weight=numpy.round(127*model.fc.true_weight()[0].detach().cpu().numpy().ravel()).astype(int)\n",
    "    second_fc_bias=numpy.round(127*model.fc.true_weight()[1].detach().cpu().numpy().ravel()).astype(int)\n",
    "    ####################################################################################\n",
    "    ## 把两个版本的差量写到文件中\n",
    "\n",
    "    out_path='./part_diff/'+str(i)+'.out'\n",
    "    ##清理文件\n",
    "    with open(out_path,'w') as binfile:\n",
    "        print('clean the ',out_path)\n",
    "    ##写入\n",
    "    with open(out_path,'ab') as binfile:\n",
    "        #################\n",
    "        for x,y in zip(first0,second0):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        xnor_diff=(first1*second1)\n",
    "        xnor_diff=bi_list_To_uint8_list(xnor_diff)\n",
    "        for t in xnor_diff:\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        xnor_diff=(first2*second2)\n",
    "        xnor_diff=bi_list_To_uint8_list(xnor_diff)\n",
    "        for t in xnor_diff:\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        xnor_diff=(first3*second3)\n",
    "        xnor_diff=bi_list_To_uint8_list(xnor_diff)\n",
    "        for t in xnor_diff:\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        xnor_diff=(first4*second4)\n",
    "        xnor_diff=bi_list_To_uint8_list(xnor_diff)\n",
    "        for t in xnor_diff:\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        xnor_diff=(first5*second5)\n",
    "        xnor_diff=bi_list_To_uint8_list(xnor_diff)\n",
    "        for t in xnor_diff:\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        for x,y in zip(first_fc_weight,second_fc_weight):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "        #################\n",
    "        for x,y in zip(first_fc_bias,second_fc_bias):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/999 [00:00<?, ?it/s]clean the  ./diff_conv/0.out\n",
      "  0%|          | 1/999 [00:03<55:22,  3.33s/it]success write the  ./diff_conv/0.out\n",
      "clean the  ./diff_conv/1.out\n",
      "  0%|          | 2/999 [00:06<54:40,  3.29s/it]success write the  ./diff_conv/1.out\n",
      "clean the  ./diff_conv/2.out\n",
      "  0%|          | 3/999 [00:09<54:44,  3.30s/it]success write the  ./diff_conv/2.out\n",
      "clean the  ./diff_conv/3.out\n",
      "  0%|          | 4/999 [00:13<55:05,  3.32s/it]success write the  ./diff_conv/3.out\n",
      "clean the  ./diff_conv/4.out\n",
      "  0%|          | 4/999 [00:15<1:03:54,  3.85s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-87392fd4d916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mbinfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_fc_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecond_fc_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import struct\n",
    "import os\n",
    "import time\n",
    "\n",
    "def file_clean(path):\n",
    "    with open(path,'w') as file:\n",
    "        pass\n",
    "    print('clean the ',path)\n",
    "    return\n",
    "\n",
    "model_path='./out/allnormal89.33/'\n",
    "\n",
    "model = my_model.VGG_SMALL_1W1A_normal().cuda()\n",
    "\n",
    "for i in tqdm(range(999)):\n",
    "#for i in (range(999)):\n",
    "    model.load_state_dict(torch.load(model_path+str(i)+'.ckpt'))\n",
    "    first0=numpy.round(127*model.conv0.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first1=numpy.round(127*model.conv1.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first2=numpy.round(127*model.conv2.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first3=numpy.round(127*model.conv3.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first4=numpy.round(127*model.conv4.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first5=numpy.round(127*model.conv5.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    first_fc_weight=numpy.round(127*model.fc.true_weight()[0].detach().cpu().numpy().ravel()).astype(int)\n",
    "    first_fc_bias=numpy.round(127*model.fc.true_weight()[1].detach().cpu().numpy().ravel()).astype(int)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path+str(i+1)+'.ckpt'))\n",
    "    second0=numpy.round(127*model.conv0.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second1=numpy.round(127*model.conv1.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second2=numpy.round(127*model.conv2.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second3=numpy.round(127*model.conv3.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second4=numpy.round(127*model.conv4.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second5=numpy.round(127*model.conv5.true_weight().detach().cpu().numpy().ravel()).astype(int)\n",
    "    second_fc_weight=numpy.round(127*model.fc.true_weight()[0].detach().cpu().numpy().ravel()).astype(int)\n",
    "    second_fc_bias=numpy.round(127*model.fc.true_weight()[0].detach().cpu().numpy().ravel()).astype(int)\n",
    "\n",
    "\n",
    "    out_path='./diff_conv/'+str(i)+'.out'\n",
    "    file_clean(out_path)\n",
    "\n",
    "    with open(out_path,'ab') as binfile:\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "# 两个[-128,+127]的数的差值范围为[-255,+255]，远远超过了int8所能表示的范围\n",
    "# 所以不能直接对两个做差得到差量\n",
    "# 将[-128,+127]变成一个有向循环的区间，差量的取值范围为[0,255]\n",
    "# 将差量表示成为下一个版本减上一个版本的值，若值大于0，则直接存储，若值小于0，则用256+结果的值存储（类似反码）\n",
    "# 在解压时，当前版本加上差量，若结果在[-128,+127]之间，则结束\n",
    "# 若结果>+127，则将结果减去256（即将+128连接到-128），则可得到正确结果\n",
    "# \n",
    "# 例如:+100->-100,差量=-200(小于0)，则保存-200+256=56\n",
    "# 恢复时，下一版本=+100+56=156>127，则减去256=156-256=100\n",
    "# \n",
    "####################################################################################\n",
    "####################################################################################\n",
    "        for x,y in zip(first0,second0):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first1,second1):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first2,second2):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first3,second3):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first4,second4):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first5,second5):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first_fc_weight,second_fc_weight):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "\n",
    "        for x,y in zip(first_fc_bias,second_fc_bias):\n",
    "            t=y-x\n",
    "            if t<0:\n",
    "                t=t+256\n",
    "            binfile.write(struct.pack('B',t))\n",
    "            \n",
    "    print('success write the ',out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4663696\n4660106\n"
     ]
    }
   ],
   "source": [
    "# 即total_paras参数不包含bn层的running_mean 和 running_var\n",
    "# 但是包括bn.weight和bn.bias\n",
    "# 因为这些参数是对输入数据的统计，不是学习得到的\n",
    "total_num = sum(model.state_dict()[i].reshape(-1).shape[0] for i in model.state_dict())\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_num)\n",
    "print(total_params)"
   ]
  }
 ]
}